{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IA COM PYTHON E LANGCHAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O que é LangChain: É um framework/ecossistema de código aberto para desenvolvimento de aplicações com grandes modelos de linguagens (LLMs). Disponível em bibliotecas Python e Java, as ferramentas e APIs do LangChain simplificam o processo de criação de aplicativos baseados em LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O Django da Inteligência Artificial ! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O ecossistema do LangChain está em acelerado crescimento e já conta com diversos  [Pacotes](https://python.langchain.com/docs/integrations/providers/):\n",
    "\n",
    "- langchain e langchain_core\n",
    "- langchain_community\n",
    "- langchain_openai\n",
    "- langchain_aws\n",
    "- langchain_chroma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se for usar o LLM da Openai tem que criar uma conta nesse [site](https://platform.openai.com/settings/organization/billing/overview) e após isso criar uma API para ser consumida dentro do LangChain, depois devemos adicionar essa API em um arquivo .env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precisamos instalar alguns pacotes no terminal: \n",
    "\n",
    "- pip install langchain \n",
    "- pip install langchain-openai\n",
    "- pip install python-decouple\n",
    "- pipi isntall langchain-community"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos conectar o LangChain as modelos de linguagem:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OPENAI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from decouple import config\n",
    "\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = config('OPENAI_API_KEY')\n",
    "\n",
    "model = OpenAI()\n",
    "\n",
    "question = input('O que deseja saber ?')\n",
    "\n",
    "response = model.invoke(\n",
    "    input=question,\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O LangChain_openai possui um pacote (lib) de CHAT e com isso conseguimos criar um chat separando mensagens de um usuário com mensagens da IA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from decouple import config\n",
    "\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage # tipos\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = config('OPENAI_API_KEY')\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model='gpt-3.5-turbo',\n",
    "\n",
    ")\n",
    "\n",
    "question = input('O que deseja saber ?')\n",
    "\n",
    "message = [\n",
    "    SystemMessage(content='Você é um assistente que fornece informações sobre figuras históricas.'), # definição do padrão da IA\n",
    "    HumanMessage(content=question), # mensagem do usuário.\n",
    "]\n",
    "\n",
    "response = model.invoke(message)\n",
    "\n",
    "print(response)\n",
    "print(response.content)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O LangChain permite a criação de templates de prompts para usar no código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from decouple import config\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage # tipos\n",
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate # templates de menssagens\n",
    "\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = config('OPENAI_API_KEY')\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model='gpt-3.5-turbo',\n",
    "\n",
    ")\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(content='Você deve responder baseado em dados geográficos de regiões do Brasil e seja o mais breve possível.'),\n",
    "        \n",
    "        HumanMessagePromptTemplate.from_template(\n",
    "            template='Por favor, me fale sobre a região {regiao}, com dados demográficos.'\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "regiao = input('sobre qual região deseja saber ?')\n",
    "\n",
    "prompt = chat_template.format_messages(regiao=regiao)\n",
    "\n",
    "print(prompt)\n",
    "\n",
    "#response = model.invoke(prompt)\n",
    "#print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos deixar agora o chat mais interativo ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from decouple import config\n",
    "from langchain.schema import SystemMessage, HumanMessage, AIMessage\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# Configuração da API Key\n",
    "os.environ['OPENAI_API_KEY'] = config('OPENAI_API_KEY')\n",
    "\n",
    "# Configurar o modelo\n",
    "model = ChatOpenAI(\n",
    "    model_name='gpt-3.5-turbo',\n",
    ")\n",
    "\n",
    "# Mensagens iniciais para o contexto do chat\n",
    "messages = [\n",
    "    SystemMessage(content='Você é um assistente que fornece informações sobre figuras históricas.')\n",
    "]\n",
    "\n",
    "print(\"Digite 'sair' para encerrar o chat.\\n\")\n",
    "\n",
    "# Loop do chat\n",
    "while True:\n",
    "    # Entrada do usuário\n",
    "    question = input('Você: ')\n",
    "\n",
    "    # Verificar se o usuário quer encerrar o chat\n",
    "    if question.lower() == 'sair':\n",
    "        print(\"Chat encerrado. Até a próxima!\")\n",
    "        break\n",
    "\n",
    "    # Adicionar a mensagem do usuário à lista de mensagens\n",
    "    messages.append(HumanMessage(content=question))\n",
    "\n",
    "    # Obter resposta do modelo\n",
    "    response = model(messages)\n",
    "\n",
    "    # Exibir resposta\n",
    "    print(\"Assistente:\", response.content)\n",
    "\n",
    "    # Adicionar a resposta da IA às mensagens para manter o contexto\n",
    "    messages.append(AIMessage(content=response.content))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos falar sobre Agentes, os Agents do LangChain possuem ferramentas (toolskits) que podem aumentar significamente o poder as IAs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from decouple import config\n",
    "\n",
    "\n",
    "from langchain.agents import create_react_agent, AgentExecutor # Função de criação de um agente. \n",
    "from langchain_community.agent_toolkits.sql.toolkit import SQLDatabaseToolkit # Todas as ferramentas que tratam o SQL.\n",
    "from langchain_community.utilities.sql_database import SQLDatabase # Classe de conexão com o banco de dados\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain import hub # armazenamento de prompts prontos da comunidade.\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Configuração da API Key\n",
    "os.environ['OPENAI_API_KEY'] = config('OPENAI_API_KEY')\n",
    "\n",
    "# Configurar o modelo\n",
    "model = ChatOpenAI(\n",
    "    model_name='gpt-3.5-turbo',\n",
    ")\n",
    "\n",
    "# Fazendo a conexão com o banco de dados\n",
    "db = SQLDatabase.from_uri('sqlite:///pop_database.db')\n",
    "\n",
    "toolkit = SQLDatabaseToolkit(\n",
    "    db=db,\n",
    "    llm=model\n",
    ") \n",
    "\n",
    "system_message = hub.pull('hwchase17/react') # Um prompt pronto de um usuário de langchain que vai ajudar a IA se localizar nas ferramentas.\n",
    "#print(system_message)\n",
    "\n",
    "# Criando o Agente:\n",
    "agent = create_react_agent(\n",
    "    llm = model,\n",
    "    tools= toolkit.get_tools(),\n",
    "    prompt = system_message,\n",
    ")\n",
    "\n",
    "# Executando o Agente:\n",
    "agent_execut = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=toolkit.get_tools(),\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "prompt = '''\n",
    "Use as ferramentas necessárias para responder perguntas relacionadas aos procedimentos que estão armazenados no banco de dados,\n",
    "pergunta {q}\n",
    "'''\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(prompt)\n",
    "\n",
    "question = input('O que deseja saber ?')\n",
    "\n",
    "output = agent_execut.invoke(\n",
    "    {\n",
    "        'input':prompt_template.format(q=question),\n",
    "    }\n",
    ")\n",
    "\n",
    "print(output.get('output'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos deixar um pouco mais interativo ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from decouple import config\n",
    "\n",
    "\n",
    "from langchain.agents import create_react_agent, AgentExecutor # Função de criação de um agente. \n",
    "from langchain_community.agent_toolkits.sql.toolkit import SQLDatabaseToolkit # Todas as ferramentas que tratam o SQL.\n",
    "from langchain_community.utilities.sql_database import SQLDatabase # Classe de conexão com o banco de dados\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain import hub # armazenamento de prompts prontos da comunidade.\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Configuração da API Key\n",
    "os.environ['OPENAI_API_KEY'] = config('OPENAI_API_KEY')\n",
    "\n",
    "# Configurar o modelo\n",
    "model = ChatOpenAI(\n",
    "    model_name='gpt-3.5-turbo',\n",
    ")\n",
    "\n",
    "# Fazendo a conexão com o banco de dados\n",
    "db = SQLDatabase.from_uri('sqlite:///pop_database.db')\n",
    "\n",
    "toolkit = SQLDatabaseToolkit(\n",
    "    db=db,\n",
    "    llm=model\n",
    ") \n",
    "\n",
    "system_message = hub.pull('hwchase17/react') # Um prompt pronto de um usuário de langchain que vai ajudar a IA se localizar nas ferramentas.\n",
    "#print(system_message)\n",
    "\n",
    "# Criando o Agente:\n",
    "agent = create_react_agent(\n",
    "    llm = model,\n",
    "    tools= toolkit.get_tools(),\n",
    "    prompt = system_message,\n",
    ")\n",
    "\n",
    "# Executando o Agente:\n",
    "agent_execut = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=toolkit.get_tools(),\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "prompt = '''\n",
    "Use as ferramentas necessárias para responder perguntas relacionadas aos procedimentos que estão armazenados no banco de dados,\n",
    "pergunta {q}\n",
    "'''\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(prompt)\n",
    "\n",
    "print(\"Digite 'Sair' para encerrar o chat . \\n\")\n",
    "\n",
    "while True:\n",
    "    question = input('O que deseja saber ?')\n",
    "    \n",
    "    if question.lower() == 'sair':\n",
    "        print(\"Chat encerrado!\")\n",
    "        break\n",
    "\n",
    "    output = agent_execut.invoke(\n",
    "        {\n",
    "            'input':prompt_template.format(q=question),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    print(output.get('output'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
